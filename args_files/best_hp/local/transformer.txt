--model_type=transformer
--num_experiment_runs=100
--checkpoint_dir=model_output/local
--learning_rate=4.642393598761296e-05
--weight_decay=0.014894906673179905
--dropout=0.07572325970197927
--encoder_length=72
--prediction_length=12
--batch_size=256
--num_epoch=100
--gradient_clip_val=0.01
--d_model=96
--nhead=3
--num_encoder_layers=3
--num_decoder_layers=6
--dim_feedforward=4096
--use_local_model